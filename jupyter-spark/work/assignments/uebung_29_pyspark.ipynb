{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bab6538",
   "metadata": {},
   "source": [
    "# Übung 2.9 Todesursachen\n",
    "Wie bereits in anderen Übungen besprochen, muss man zuerst wieder die Daten in das HDFS laden. Dazu habe ich wieder die Datei `death2016.csv` in das Volume des `namenode` Containers hineinkopiert, ich bin in das dazugehörende Verzeichnis in dem `namenode` Container hineingegangen mittels `docker exec -it namenode bash` und `cd /hadoop-data`, und schließlich habe ich die Daten in das HDFS mittels `hadoop fs -copyFromLocal death2016.csv workspace/pyspark` kopiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0709a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, BooleanType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions\n",
    "from pyspark.sql import dataframe\n",
    "from pyspark.sql.functions import to_timestamp, to_date, year, dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e30379",
   "metadata": {},
   "source": [
    "## Einlesen der Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f595dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session & context\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('spark://spark-master:7077') \\\n",
    "    .appName(\"uebung_29\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43684d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema of death file\n",
    "death_cols = [\n",
    "    StructField('country', StringType()),\n",
    "    StructField('cause_no', IntegerType()),\n",
    "    StructField('cause_name', StringType()),\n",
    "    StructField('sex', StringType()),\n",
    "    StructField('age', IntegerType()),\n",
    "    StructField('age_group', StringType()),\n",
    "]\n",
    "\n",
    "for year in range(2000, 2017):\n",
    "    death_low_up = [StructField(f'deaths_{year}', FloatType()),\n",
    "                    StructField(f'low_{year}', FloatType()),\n",
    "                    StructField(f'up_{year}', FloatType())]\n",
    "    death_cols += death_low_up\n",
    "    \n",
    "death_schema = StructType(death_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5def134c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- cause_no: integer (nullable = true)\n",
      " |-- cause_name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- deaths_2000: float (nullable = true)\n",
      " |-- low_2000: float (nullable = true)\n",
      " |-- up_2000: float (nullable = true)\n",
      " |-- deaths_2001: float (nullable = true)\n",
      " |-- low_2001: float (nullable = true)\n",
      " |-- up_2001: float (nullable = true)\n",
      " |-- deaths_2002: float (nullable = true)\n",
      " |-- low_2002: float (nullable = true)\n",
      " |-- up_2002: float (nullable = true)\n",
      " |-- deaths_2003: float (nullable = true)\n",
      " |-- low_2003: float (nullable = true)\n",
      " |-- up_2003: float (nullable = true)\n",
      " |-- deaths_2004: float (nullable = true)\n",
      " |-- low_2004: float (nullable = true)\n",
      " |-- up_2004: float (nullable = true)\n",
      " |-- deaths_2005: float (nullable = true)\n",
      " |-- low_2005: float (nullable = true)\n",
      " |-- up_2005: float (nullable = true)\n",
      " |-- deaths_2006: float (nullable = true)\n",
      " |-- low_2006: float (nullable = true)\n",
      " |-- up_2006: float (nullable = true)\n",
      " |-- deaths_2007: float (nullable = true)\n",
      " |-- low_2007: float (nullable = true)\n",
      " |-- up_2007: float (nullable = true)\n",
      " |-- deaths_2008: float (nullable = true)\n",
      " |-- low_2008: float (nullable = true)\n",
      " |-- up_2008: float (nullable = true)\n",
      " |-- deaths_2009: float (nullable = true)\n",
      " |-- low_2009: float (nullable = true)\n",
      " |-- up_2009: float (nullable = true)\n",
      " |-- deaths_2010: float (nullable = true)\n",
      " |-- low_2010: float (nullable = true)\n",
      " |-- up_2010: float (nullable = true)\n",
      " |-- deaths_2011: float (nullable = true)\n",
      " |-- low_2011: float (nullable = true)\n",
      " |-- up_2011: float (nullable = true)\n",
      " |-- deaths_2012: float (nullable = true)\n",
      " |-- low_2012: float (nullable = true)\n",
      " |-- up_2012: float (nullable = true)\n",
      " |-- deaths_2013: float (nullable = true)\n",
      " |-- low_2013: float (nullable = true)\n",
      " |-- up_2013: float (nullable = true)\n",
      " |-- deaths_2014: float (nullable = true)\n",
      " |-- low_2014: float (nullable = true)\n",
      " |-- up_2014: float (nullable = true)\n",
      " |-- deaths_2015: float (nullable = true)\n",
      " |-- low_2015: float (nullable = true)\n",
      " |-- up_2015: float (nullable = true)\n",
      " |-- deaths_2016: float (nullable = true)\n",
      " |-- low_2016: float (nullable = true)\n",
      " |-- up_2016: float (nullable = true)\n",
      "\n",
      "None\n",
      "+-------+--------+----------+----+---+---------+-----------+--------+--------+-----------+---------+--------+-----------+---------+--------+-----------+--------+--------+-----------+--------+-------+-----------+---------+--------+-----------+---------+-------+-----------+--------+---------+-----------+---------+--------+-----------+---------+---------+-----------+---------+--------+-----------+---------+-------+-----------+---------+--------+-----------+--------+--------+-----------+---------+-------+-----------+---------+-------+-----------+---------+--------+\n",
      "|country|cause_no|cause_name| sex|age|age_group|deaths_2000|low_2000| up_2000|deaths_2001| low_2001| up_2001|deaths_2002| low_2002| up_2002|deaths_2003|low_2003| up_2003|deaths_2004|low_2004|up_2004|deaths_2005| low_2005| up_2005|deaths_2006| low_2006|up_2006|deaths_2007|low_2007|  up_2007|deaths_2008| low_2008| up_2008|deaths_2009| low_2009|  up_2009|deaths_2010| low_2010| up_2010|deaths_2011| low_2011|up_2011|deaths_2012| low_2012| up_2012|deaths_2013|low_2013| up_2013|deaths_2014| low_2014|up_2014|deaths_2015| low_2015|up_2015|deaths_2016| low_2016| up_2016|\n",
      "+-------+--------+----------+----+---+---------+-----------+--------+--------+-----------+---------+--------+-----------+---------+--------+-----------+--------+--------+-----------+--------+-------+-----------+---------+--------+-----------+---------+-------+-----------+--------+---------+-----------+---------+--------+-----------+---------+---------+-----------+---------+--------+-----------+---------+-------+-----------+---------+--------+-----------+--------+--------+-----------+---------+-------+-----------+---------+-------+-----------+---------+--------+\n",
      "|    AFG|       0|All Causes|BTSX|  0| DAYS0-28|  60868.906|34246.64|90078.48|  61388.668|34790.637|91407.21|   61690.71|34614.418|91951.03|   61799.99|34357.53|92295.98|   61605.94|34040.51|91949.8|  61179.906|33562.926|91600.87|   60374.83|32761.854|90251.5|   59299.37|31961.84|88785.445|  57981.242|30966.725|87280.66|  56357.633|29882.412|85091.586|  54726.305|28686.979|82303.52|  52933.816|27421.086|80587.0|  51277.246|26259.059|79178.71|  49682.727|25241.94|78153.92|  48282.793|24284.793|76879.9|   46953.26|22766.672|76307.8|  45899.395|22255.672|74595.06|\n",
      "+-------+--------+----------+----+---+---------+-----------+--------+--------+-----------+---------+--------+-----------+---------+--------+-----------+--------+--------+-----------+--------+-------+-----------+---------+--------+-----------+---------+-------+-----------+--------+---------+-----------+---------+--------+-----------+---------+---------+-----------+---------+--------+-----------+---------+-------+-----------+---------+--------+-----------+--------+--------+-----------+---------+-------+-----------+---------+-------+-----------+---------+--------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read in death file\n",
    "file_path = 'hdfs://namenode:8020/user/root/workspace/pyspark/death2016.csv'\n",
    "deaths = spark.read.csv(file_path, death_schema)\n",
    "print(deaths.printSchema())\n",
    "print(deaths.show(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0cea9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a temporary view so that we can execute HiveQL statements\n",
    "deaths.createOrReplaceTempView('deaths')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda36b38",
   "metadata": {},
   "source": [
    "## Teilaufgabe 1\n",
    "Todesursache mit Anzahl an Todesfällen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8af3b5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiveQL statement: select cause_name, sum(deaths_2000+deaths_2001+deaths_2002+deaths_2003+deaths_2004+deaths_2005+deaths_2006+deaths_2007+deaths_2008+deaths_2009+deaths_2010+deaths_2011+deaths_2012+deaths_2013+deaths_2014+deaths_2015+deaths_2016) as total from deaths where country = \"DEU\" group by cause_name order by total desc;\n",
      "+--------------------+--------------------+\n",
      "|          cause_name|               total|\n",
      "+--------------------+--------------------+\n",
      "|          All Causes|1.4551129185058594E7|\n",
      "|Noncommunicable d...|1.3325673312011719E7|\n",
      "|Cardiovascular di...|    6070731.26240921|\n",
      "| Malignant neoplasms|   3786898.846229553|\n",
      "|Ischaemic heart d...|   3556194.562406063|\n",
      "|              Stroke|  1135246.9709677696|\n",
      "|Other circulatory...|   888717.4789266586|\n",
      "|Respiratory diseases|   875449.3753051758|\n",
      "|Trachea; bronchus...|    738239.602329731|\n",
      "|  Digestive diseases|   737520.3945465088|\n",
      "|Chronic obstructi...|   711904.0276870728|\n",
      "|    Ischaemic stroke|   681536.0698115826|\n",
      "|Communicable; mat...|   656817.6657104492|\n",
      "|Neurological cond...|     642689.35828197|\n",
      "|            Injuries|   568638.2004394531|\n",
      "|Colon and rectum ...|   511490.6223897934|\n",
      "| Haemorrhagic stroke|  453710.94087934494|\n",
      "|   Diabetes mellitus|    404191.826438427|\n",
      "|Respiratory infec...|  398004.56506347656|\n",
      "|Lower respiratory...|  394641.04653930664|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "death_cols = [f'deaths_{year}' for year in range(2000, 2017)]\n",
    "death_cols_str = '+'.join(death_cols)\n",
    "stmt = (f'select cause_name, sum({death_cols_str}) as total '\n",
    "       'from deaths where country = \"DEU\" '\n",
    "        'group by cause_name '\n",
    "       'order by total desc;')\n",
    "print('HiveQL statement:', stmt)\n",
    "death_cause_ger = spark.sql(stmt)\n",
    "death_cause_ger.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4cff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEVER FORGET to stop the session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
